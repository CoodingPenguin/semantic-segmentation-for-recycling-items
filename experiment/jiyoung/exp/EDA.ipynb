{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f304a72b-36be-40fb-a223-b31ba8e777ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import time\n",
    "import json\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from utils import label_accuracy_score, get_miou, FocalTverskyLoss\n",
    "import cv2\n",
    "\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import torch.nn.functional as F\n",
    "from torch_optimizer import adamp\n",
    "from utils import *\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# 전처리를 위한 라이브러리\n",
    "from pycocotools.coco import COCO\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import segmentation_models_pytorch as smp\n",
    "from vgg16 import FCN8s\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from dice_loss import SoftDiceLoss\n",
    "\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71faced8-07fb-47ed-b1f4-e23e618645a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pytorch version: 1.4.0\n",
      "GPU 사용 가능 여부: True\n",
      "Tesla P40\n",
      "1\n",
      "Number of categories: 11\n",
      "Number of annotations: 21116\n",
      "Number of images: 2617\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"pytorch version: {}\".format(torch.__version__))\n",
    "print(\"GPU 사용 가능 여부: {}\".format(torch.cuda.is_available()))\n",
    "\n",
    "print(torch.cuda.get_device_name(0))\n",
    "print(torch.cuda.device_count())\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"  # GPU 사용 가능 여부에 따라 device 정보 저장\n",
    "\n",
    "# seed 고정\n",
    "random_seed = 21\n",
    "torch.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed(random_seed)\n",
    "# torch.cuda.manual_seed_all(random_seed) # if use multi-GPU\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(random_seed)\n",
    "random.seed(random_seed)\n",
    "\n",
    "\n",
    "dataset_path = \"/opt/ml/input/data\"\n",
    "anns_file_path = dataset_path + \"/\" + \"train.json\"\n",
    "\n",
    "# Read annotations\n",
    "with open(anns_file_path, \"r\") as f:\n",
    "    dataset = json.loads(f.read())\n",
    "\n",
    "categories = dataset[\"categories\"]\n",
    "anns = dataset[\"annotations\"]\n",
    "imgs = dataset[\"images\"]\n",
    "nr_cats = len(categories)\n",
    "nr_annotations = len(anns)\n",
    "nr_images = len(imgs)\n",
    "\n",
    "# Load categories and super categories\n",
    "cat_names = []  # 모든 카테고리 이름\n",
    "for cat_it in categories:\n",
    "    cat_names.append(cat_it[\"name\"])\n",
    "\n",
    "print(\"Number of categories:\", nr_cats)\n",
    "print(\"Number of annotations:\", nr_annotations)\n",
    "print(\"Number of images:\", nr_images)\n",
    "\n",
    "# Count annotations\n",
    "cat_histogram = np.zeros(nr_cats, dtype=int)\n",
    "for ann in anns:\n",
    "    cat_histogram[ann[\"category_id\"]] += 1  # 카테고리별 개수 카운트\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame({\"Categories\": cat_names, \"Number of annotations\": cat_histogram})\n",
    "\n",
    "# category labeling\n",
    "sorted_temp_df = df.sort_index()\n",
    "\n",
    "# background = 0 에 해당되는 label 추가 후 기존들을 모두 label + 1 로 설정\n",
    "sorted_df = pd.DataFrame([\"Backgroud\"], columns=[\"Categories\"])\n",
    "sorted_df = sorted_df.append(sorted_temp_df, ignore_index=True)\n",
    "\n",
    "# class (Categories) 에 따른 index 확인 (0~11 : 총 12개)\n",
    "# sorted_df\n",
    "\n",
    "category_names = list(sorted_df.Categories)\n",
    "\n",
    "\n",
    "def get_classname(classID, cats):\n",
    "    for i in range(len(cats)):\n",
    "        if cats[i][\"id\"] == classID:\n",
    "            return cats[i][\"name\"]\n",
    "    return \"None\"\n",
    "\n",
    "\n",
    "class CustomDataLoader(Dataset):\n",
    "    \"\"\"COCO format\"\"\"\n",
    "\n",
    "    def __init__(self, data_dir, mode=\"train\", transform=None):\n",
    "        super().__init__()\n",
    "        self.mode = mode\n",
    "        self.transform = transform\n",
    "        self.coco = COCO(data_dir)\n",
    "\n",
    "    def __getitem__(self, index: int):\n",
    "        # dataset이 index되어 list처럼 동작\n",
    "        image_id = self.coco.getImgIds(imgIds=index)\n",
    "        image_infos = self.coco.loadImgs(image_id)[0]\n",
    "\n",
    "        # cv2 를 활용하여 image 불러오기\n",
    "        images = cv2.imread(os.path.join(dataset_path, image_infos[\"file_name\"]))\n",
    "        images = cv2.cvtColor(images, cv2.COLOR_BGR2RGB).astype(np.float32)\n",
    "        #         images /= 255.0\n",
    "\n",
    "        if self.mode in (\"train\"):\n",
    "            ann_ids = self.coco.getAnnIds(imgIds=image_infos[\"id\"])\n",
    "            anns = self.coco.loadAnns(ann_ids)\n",
    "\n",
    "            # Load the categories in a variable\n",
    "            cat_ids = self.coco.getCatIds()\n",
    "            cats = self.coco.loadCats(cat_ids)\n",
    "\n",
    "            # masks : size가 (height x width)인 2D\n",
    "            # 각각의 pixel 값에는 \"category id + 1\" 할당\n",
    "            # Background = 0\n",
    "            masks = np.zeros((12, image_infos[\"height\"], image_infos[\"width\"]))\n",
    "            # Unknown = 1, General trash = 2, ... , Cigarette = 11\n",
    "            for i in range(len(anns)):\n",
    "                className = get_classname(anns[i][\"category_id\"], cats)\n",
    "                pixel_value = category_names.index(className)\n",
    "                masks[pixel_value] = self.coco.annToMask(anns[i])\n",
    "\n",
    "            masks = masks.astype(np.float32)\n",
    "\n",
    "            # transform -> albumentations 라이브러리 활용\n",
    "            if self.transform is not None:\n",
    "                transformed = self.transform(image=images, mask=masks)\n",
    "                images = transformed[\"image\"]\n",
    "                masks = transformed[\"mask\"]\n",
    "\n",
    "            return images, masks, image_infos\n",
    "\n",
    "        elif self.mode in (\"val\"):\n",
    "            ann_ids = self.coco.getAnnIds(imgIds=image_infos[\"id\"])\n",
    "            anns = self.coco.loadAnns(ann_ids)\n",
    "\n",
    "            # Load the categories in a variable\n",
    "            cat_ids = self.coco.getCatIds()\n",
    "            cats = self.coco.loadCats(cat_ids)\n",
    "\n",
    "            # masks : size가 (height x width)인 2D\n",
    "            # 각각의 pixel 값에는 \"category id + 1\" 할당\n",
    "            # Background = 0\n",
    "            masks = np.zeros((image_infos[\"height\"], image_infos[\"width\"]))\n",
    "            # Unknown = 1, General trash = 2, ... , Cigarette = 11\n",
    "            for i in range(len(anns)):\n",
    "                className = get_classname(anns[i][\"category_id\"], cats)\n",
    "                pixel_value = category_names.index(className)\n",
    "                masks = np.maximum(self.coco.annToMask(anns[i]) * pixel_value, masks)\n",
    "            masks = masks.astype(np.float32)\n",
    "\n",
    "            # transform -> albumentations 라이브러리 활용\n",
    "            if self.transform is not None:\n",
    "                transformed = self.transform(image=images, mask=masks)\n",
    "                images = transformed[\"image\"]\n",
    "                masks = transformed[\"mask\"]\n",
    "\n",
    "            return images, masks, image_infos\n",
    "\n",
    "        if self.mode == \"test\":\n",
    "            # transform -> albumentations 라이브러리 활용\n",
    "            if self.transform is not None:\n",
    "                transformed = self.transform(image=images)\n",
    "                images = transformed[\"image\"]\n",
    "\n",
    "            return images, image_infos\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        # 전체 dataset의 size를 return\n",
    "        return len(self.coco.getImgIds())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41daaa6b-3c30-4d11-a84b-5dd8e7a9c346",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train.json / validation.json / test.json 디렉토리 설정\n",
    "train_path = dataset_path + \"/train.json\"\n",
    "val_path = dataset_path + \"/val.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07f91957-a14a-49ba-a529-ecfd04db00c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.91s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "coco = COCO(val_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fb3279de-4e1a-40f2-b054-09857aea25c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "annsIds = coco.getAnnIds(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7a14f185-7949-48b3-b0ab-c6c0ce38bfdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "anns = coco.loadAnns(annsIds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cd8d4373-a55b-49b4-affe-11c0a53319f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(512, 512)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coco.annToMask(anns[0]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f37d3c38-a603-4e49-8015-9ae840313986",
   "metadata": {},
   "outputs": [],
   "source": [
    "bb = np.zeros((2,4,4), dtype=np.ubyte)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "40698b01-43c2-4b09-aa9d-71f93884e8ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0, 0, 0, 0],\n",
       "        [0, 0, 0, 0],\n",
       "        [0, 0, 0, 0],\n",
       "        [0, 0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0, 0],\n",
       "        [0, 0, 0, 0],\n",
       "        [0, 0, 0, 0],\n",
       "        [0, 0, 0, 0]]], dtype=uint8)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0eaa6371-803b-43c5-a891-0e632226559a",
   "metadata": {},
   "outputs": [],
   "source": [
    "bb[0] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "03b32a60-0aa5-4fb7-8df8-20fde1d8730c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('uint8')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bb[0].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bfb04c9c-3115-4f42-a9ad-f24354c50e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cc = np.zeros((4,4), dtype=np.ubyte)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c3babe05-cb2c-4f9f-9f98-93725384b55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cc[0] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e820dd8b-0fc2-4286-8601-d286300c8a7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1, 1],\n",
       "       [0, 0, 0, 0],\n",
       "       [0, 0, 0, 0],\n",
       "       [0, 0, 0, 0]], dtype=uint8)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "978c54e3-5f6a-4678-acfa-6c531b58bca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "bb[1] = (bb[1] == 1) | (cc == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c933bbb9-8ad7-4701-8ea0-3c4e6600d0ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1, 1, 1, 1],\n",
       "        [1, 1, 1, 1],\n",
       "        [1, 1, 1, 1],\n",
       "        [1, 1, 1, 1]],\n",
       "\n",
       "       [[1, 1, 1, 1],\n",
       "        [0, 0, 0, 0],\n",
       "        [0, 0, 0, 0],\n",
       "        [0, 0, 0, 0]]], dtype=uint8)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3bc446f-d8ad-4f85-8bfe-0bf7f01c478a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
